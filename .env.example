# Pulser Web Interface - Environment Variables

# Backend Configuration
PORT=3333
LOG_LEVEL=info

# LLM Configuration
# Available providers: claude, openai, mistral, deepseekr1, local
LLM_PROVIDER=claude

# Claude Configuration (Anthropic)
CLAUDE_MODEL=claude-3-sonnet-20240229
CLAUDE_API_KEY=your_claude_api_key_here

# OpenAI Configuration
OPENAI_MODEL=gpt-4-turbo
OPENAI_API_KEY=your_openai_api_key_here

# Mistral Configuration
MISTRAL_MODEL=mistral-large-latest
MISTRAL_API_KEY=your_mistral_api_key_here

# DeepSeekr1 Configuration (Local)
DEEPSEEKR1_API_URL=http://localhost:8080/v1/chat/completions

# Local LLM Configuration (e.g., Ollama)
LOCAL_LLM_ENDPOINT=http://localhost:11434/v1/chat/completions

# Frontend Configuration 
NEXT_PUBLIC_API_URL=http://localhost:3333

# Vercel Deployment
VERCEL_PROJECT_ID=your_vercel_project_id
VERCEL_ORG_ID=your_vercel_org_id